{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9719317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Matrix:\n",
      "[[0 1 1 1 0 0 1 0 1]\n",
      " [0 2 0 1 0 1 1 0 1]\n",
      " [1 0 0 1 1 0 1 1 1]\n",
      " [0 1 1 1 0 0 1 0 1]]\n",
      "\n",
      "Feature Names:\n",
      "['and' 'document' 'first' 'is' 'one' 'second' 'the' 'third' 'this']\n",
      "\n",
      "Normalized Count Occurrence (TF):\n",
      "[[0.         0.2        0.2        0.2        0.         0.\n",
      "  0.2        0.         0.2       ]\n",
      " [0.         0.33333333 0.         0.16666667 0.         0.16666667\n",
      "  0.16666667 0.         0.16666667]\n",
      " [0.16666667 0.         0.         0.16666667 0.16666667 0.\n",
      "  0.16666667 0.16666667 0.16666667]\n",
      " [0.         0.2        0.2        0.2        0.         0.\n",
      "  0.2        0.         0.2       ]]\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]\n",
      " [0.         0.6876236  0.         0.28108867 0.         0.53864762\n",
      "  0.28108867 0.         0.28108867]\n",
      " [0.51184851 0.         0.         0.26710379 0.51184851 0.\n",
      "  0.26710379 0.51184851 0.26710379]\n",
      " [0.         0.46979139 0.58028582 0.38408524 0.         0.\n",
      "  0.38408524 0.         0.38408524]]\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_18920/1169302130.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdense_array_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "# pip install scikit-learn gensim nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Sample data\n",
    "documents = [\n",
    "    \"This is the first document.\",\n",
    "    \"This document is the second document.\",\n",
    "    \"And this is the third one.\",\n",
    "    \"Is this the first document?\",\n",
    "]\n",
    "\n",
    "# Create the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_bow = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Get the feature names (words)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Convert the result to a dense array\n",
    "dense_array_bow = X_bow.toarray()\n",
    "\n",
    "# Display the BoW matrix\n",
    "print(\"Bag-of-Words Matrix:\")\n",
    "print(dense_array_bow)\n",
    "\n",
    "# Display feature names\n",
    "print(\"\\nFeature Names:\")\n",
    "print(feature_names)\n",
    "\n",
    "# Calculate Term Frequency (TF)\n",
    "TF = dense_array_bow / dense_array_bow.sum(axis=1, keepdims=True)\n",
    "\n",
    "# Display normalized count occurrence (TF)\n",
    "print(\"\\nNormalized Count Occurrence (TF):\")\n",
    "print(TF)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# Create the TF-IDF transformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "# Fit and transform the TF matrix\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_bow)\n",
    "\n",
    "# Convert the result to a dense array\n",
    "dense_array_tfidf = X_tfidf.toarray()\n",
    "\n",
    "# Display the TF-IDF matrix\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(dense_array_tfidf)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "# Tokenize the documents\n",
    "tokenized_documents = [word_tokenize(doc.lower()) for doc in documents]\n",
    "\n",
    "# Train Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=tokenized_documents, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Example: Get the embedding for the word 'document'\n",
    "embedding_document = word2vec_model.wv['document']\n",
    "print(\"\\nWord2Vec Embedding for 'document':\")\n",
    "print(embedding_document)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f675669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a55d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
